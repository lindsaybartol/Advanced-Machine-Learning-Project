{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import necessary libraries\n",
    "import os\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "import shutil\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "BATCH = 16\n",
    "IM_SIZE = 224\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "MODEL_PATH = r\"C:\\Users\\linds\\OneDrive\\Documents\\MSBA-lindsayslaptop\\Fall\\Advanced Machine Learning\\Best Model.pth\"\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(r\"C:\\ML_Project_Data\\train.csv\")\n",
    "\n",
    "# Filter dataset with hotel_ids >= 20\n",
    "s1 = df[\"hotel_id\"].value_counts()\n",
    "s2 = s1[s1 >= 20]\n",
    "hotel_id_list = s2.index.tolist()\n",
    "df1 = df[df[\"hotel_id\"].isin(hotel_id_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of classes: 1062\n",
      "Total number of images: 38389\n"
     ]
    }
   ],
   "source": [
    "# How many classes do we have and how much total data?\n",
    "\n",
    "num_classes = len(df1['hotel_id'].unique())\n",
    "print(f\"Number of classes: {num_classes}\")\n",
    "\n",
    "num_images = len(df1)\n",
    "print(f\"Total number of images: {num_images}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-test split (90:10)\n",
    "train_df, test_df = train_test_split(df1, test_size=0.1, stratify=df1['hotel_id'], random_state=42)\n",
    "\n",
    "# Map hotel_id to indices for classification\n",
    "unique_hotel_ids = sorted(train_df['hotel_id'].unique())\n",
    "hotel_id_to_index = {hotel_id: idx for idx, hotel_id in enumerate(unique_hotel_ids)}\n",
    "index_to_hotel_id = {idx: hotel_id for hotel_id, idx in hotel_id_to_index.items()}\n",
    "\n",
    "# Add the class index to the DataFrame\n",
    "train_df['class_index'] = train_df['hotel_id'].map(hotel_id_to_index)\n",
    "test_df['class_index'] = test_df['hotel_id'].map(hotel_id_to_index)\n",
    "\n",
    "# Define transformations\n",
    "Transform = transforms.Compose([\n",
    "    transforms.Resize((IM_SIZE, IM_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
    "])\n",
    "\n",
    "# Dataset Class\n",
    "class HotelImageDataset(Dataset):\n",
    "    def __init__(self, df, image_dir, transform=None):\n",
    "        self.df = df\n",
    "        self.image_dir = image_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.df.iloc[idx]['image']\n",
    "        label = self.df.iloc[idx]['class_index']\n",
    "        img_path = os.path.join(self.image_dir, str(self.df.iloc[idx]['chain']), img_name)\n",
    "        \n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize datasets and loaders\n",
    "image_dir = r\"C:\\ML_Project_Data\\train_images\"\n",
    "test_dataset = HotelImageDataset(test_df, image_dir, Transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\linds\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\linds\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# Initialize the model\n",
    "num_classes = len(unique_hotel_ids)  # Ensure this matches your friend's training\n",
    "model = models.resnet50(pretrained=False)  # Pretrained is False since we are loading weights\n",
    "model.fc = nn.Linear(model.fc.in_features, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\linds\\AppData\\Local\\Temp\\ipykernel_8928\\1918255738.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(MODEL_PATH, map_location=DEVICE))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=2048, out_features=1062, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the model weights\n",
    "model.load_state_dict(torch.load(MODEL_PATH, map_location=DEVICE))\n",
    "model = model.to(DEVICE)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 240/240 [04:39<00:00,  1.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 1.5563, Top-1 Accuracy: 73.35%, Top-5 Accuracy: 86.35%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Validation code\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "TOP_X = 5\n",
    "\n",
    "val_loss = 0.0\n",
    "correct = 0\n",
    "total = 0\n",
    "topX_correct = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in tqdm(test_loader, desc=\"Validation\"):\n",
    "        images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        val_loss += loss.item()\n",
    "\n",
    "        # Top-1 accuracy\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "        # Top-5 accuracy\n",
    "        _, predicted_topX = outputs.data.topk(TOP_X, dim=1, largest=True, sorted=True)\n",
    "        labels_expanded = labels.view(-1, 1).expand_as(predicted_topX)\n",
    "        topX_correct += (predicted_topX == labels_expanded).sum().item()\n",
    "\n",
    "avg_val_loss = val_loss / len(test_loader)\n",
    "top1_accuracy = 100 * correct / total\n",
    "topX_accuracy = 100 * topX_correct / total\n",
    "\n",
    "print(f\"Validation Loss: {avg_val_loss:.4f}, Top-1 Accuracy: {top1_accuracy:.2f}%, Top-{TOP_X} Accuracy: {topX_accuracy:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring Image Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Model on Test Data: 100%|██████████| 240/240 [03:20<00:00,  1.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     hotel_id  image_count  correct_count  accuracy\n",
      "172     36363           10              7  0.700000\n",
      "505     53586           10              6  0.600000\n",
      "38      60181            9              8  0.888889\n",
      "546     17759            9              8  0.888889\n",
      "557      4869            9              8  0.888889\n",
      "643     64314            9              8  0.888889\n",
      "315     18807            9              7  0.777778\n",
      "15       9520            8              8  1.000000\n",
      "112     18002            8              8  1.000000\n",
      "116     58884            8              8  1.000000\n",
      "156     28917            8              8  1.000000\n",
      "173     24833            8              8  1.000000\n",
      "177      6524            8              8  1.000000\n",
      "223     13849            8              8  1.000000\n",
      "227     16161            8              8  1.000000\n",
      "232     56874            8              8  1.000000\n",
      "292     32791            8              8  1.000000\n",
      "322     24421            8              8  1.000000\n",
      "434     10263            8              8  1.000000\n",
      "442     18661            8              8  1.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#okay let's see what hotels had the most images in the test data nad their accuracy to find the best options for TCAV\n",
    "\n",
    "# Initialize variables for storing results\n",
    "hotel_image_counts = {}\n",
    "hotel_correct_counts = {}\n",
    "\n",
    "# Ensure the model is in evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Initialize lists to store predictions and labels for all test samples\n",
    "all_predictions = []\n",
    "all_labels = []\n",
    "\n",
    "# Process test data\n",
    "with torch.no_grad():\n",
    "    for images, labels in tqdm(test_loader, desc=\"Evaluating Model on Test Data\"):\n",
    "        images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "\n",
    "        # Get model predictions\n",
    "        outputs = model(images)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "\n",
    "        # Collect predictions and labels for all samples\n",
    "        all_predictions.extend(preds.cpu().numpy())  # Append batch predictions\n",
    "        all_labels.extend(labels.cpu().numpy())     # Append batch true labels\n",
    "\n",
    "        # Loop through each image in the batch\n",
    "        for label, pred in zip(labels.cpu().numpy(), preds.cpu().numpy()):\n",
    "            hotel_id = index_to_hotel_id[label]  # Map class index back to hotel_id\n",
    "\n",
    "            # Update image counts for this hotel ID\n",
    "            if hotel_id not in hotel_image_counts:\n",
    "                hotel_image_counts[hotel_id] = 0\n",
    "                hotel_correct_counts[hotel_id] = 0\n",
    "\n",
    "            hotel_image_counts[hotel_id] += 1\n",
    "\n",
    "            # Check if the prediction was correct\n",
    "            if label == pred:\n",
    "                hotel_correct_counts[hotel_id] += 1\n",
    "\n",
    "# Create a DataFrame to analyze the results\n",
    "results_df = pd.DataFrame({\n",
    "    \"hotel_id\": list(hotel_image_counts.keys()),\n",
    "    \"image_count\": list(hotel_image_counts.values()),\n",
    "    \"correct_count\": list(hotel_correct_counts.values())\n",
    "})\n",
    "\n",
    "# Calculate accuracy for each hotel ID\n",
    "results_df[\"accuracy\"] = results_df[\"correct_count\"] / results_df[\"image_count\"]\n",
    "\n",
    "# Sort by the number of images and take the top 20 hotel IDs\n",
    "top_20_hotels = results_df.sort_values(by=[\"image_count\", \"accuracy\"], ascending=[False, False]).head(20)\n",
    "\n",
    "# Display the results\n",
    "print(top_20_hotels)\n",
    "\n",
    "# Ensure all predictions and labels align with test_df\n",
    "assert len(all_predictions) == len(test_df), \"Mismatch between predictions and test dataset size\"\n",
    "assert len(all_labels) == len(test_df), \"Mismatch between labels and test dataset size\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      hotel_id  image_count  correct_count  accuracy\n",
      "51       35545            5              0       0.0\n",
      "175      15195            4              0       0.0\n",
      "915      33836            4              0       0.0\n",
      "176      41106            3              0       0.0\n",
      "341      33839            3              0       0.0\n",
      "498      30636            3              0       0.0\n",
      "604      37077            3              0       0.0\n",
      "711       8439            3              0       0.0\n",
      "719      16978            3              0       0.0\n",
      "737      35739            3              0       0.0\n",
      "794      17451            3              0       0.0\n",
      "800      49015            3              0       0.0\n",
      "958      52588            3              0       0.0\n",
      "1052     14388            3              0       0.0\n",
      "3        65273            2              0       0.0\n",
      "13       42982            2              0       0.0\n",
      "31       61142            2              0       0.0\n",
      "45        6800            2              0       0.0\n",
      "65       12649            2              0       0.0\n",
      "75        5257            2              0       0.0\n"
     ]
    }
   ],
   "source": [
    "# Sort by the number of images and take the top 20 hotel IDs\n",
    "bottom_20_hotels = results_df.sort_values(by=[\"accuracy\", \"image_count\"], ascending=[True, False]).head(20)\n",
    "\n",
    "# Display the results\n",
    "print(bottom_20_hotels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hotel ID 60181: 86 images\n",
      "Hotel ID 17759: 84 images\n",
      "Hotel ID 4869: 84 images\n",
      "Hotel ID 64314: 87 images\n",
      "Hotel ID 18807: 92 images\n",
      "Hotel ID 35545: 48 images\n",
      "Hotel ID 15195: 35 images\n",
      "Hotel ID 33836: 41 images\n",
      "Hotel ID 41106: 28 images\n",
      "Hotel ID 33839: 32 images\n"
     ]
    }
   ],
   "source": [
    "#let's look at how many image they were trained on\n",
    "\n",
    "# Base directory containing the training data\n",
    "csv_path = r\"C:\\ML_Project_Data\\train.csv\"\n",
    "\n",
    "# Load the CSV file\n",
    "try:\n",
    "    df = pd.read_csv(csv_path)\n",
    "except FileNotFoundError:\n",
    "    print(f\"File not found: {csv_path}\")\n",
    "    exit()\n",
    "\n",
    "# List of hotel IDs to count images for\n",
    "hotel_ids = [60181, 17759, 4869, 64314, 18807, 35545, 15195, 33836, 41106, 33839]\n",
    "\n",
    "# Count the number of images for each hotel ID\n",
    "image_counts = df['hotel_id'].value_counts()\n",
    "\n",
    "# Filter counts for the specified hotel IDs\n",
    "hotel_image_counts = {hotel_id: image_counts.get(hotel_id, 0) for hotel_id in hotel_ids}\n",
    "\n",
    "# Display the results\n",
    "for hotel_id, count in hotel_image_counts.items():\n",
    "    print(f\"Hotel ID {hotel_id}: {count} images\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image organization complete!\n"
     ]
    }
   ],
   "source": [
    "# Now let's create files of the images we might use TCAV on to explore concepts\n",
    "\n",
    "# Define the hotel IDs and corresponding image directories\n",
    "target_hotel_ids = [60181, 17759, 4869, 64314, 18807, 9520, 18002, 58884]\n",
    "\n",
    "# Paths\n",
    "image_dir = r\"C:\\ML_Project_Data\\train_images\"  # Root directory of images\n",
    "output_dir = r\"C:\\ML_Project_Data\\TCAV_Hotel_Images\"  # Output directory for organizing images\n",
    "\n",
    "# Create output directory if it doesn't exist\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Iterate through the test set\n",
    "for hotel_id in target_hotel_ids:\n",
    "    # Create directories for the hotel\n",
    "    hotel_dir = os.path.join(output_dir, str(hotel_id))\n",
    "    correct_dir = os.path.join(hotel_dir, \"correct\")\n",
    "    incorrect_dir = os.path.join(hotel_dir, \"incorrect\")\n",
    "    os.makedirs(correct_dir, exist_ok=True)\n",
    "    os.makedirs(incorrect_dir, exist_ok=True)\n",
    "\n",
    "    # Filter test set for the current hotel ID\n",
    "    hotel_images = test_df[test_df['hotel_id'] == hotel_id]\n",
    "    \n",
    "    # Iterate through the images for this hotel ID\n",
    "    for idx, row in hotel_images.iterrows():\n",
    "        image_name = row['image']\n",
    "        chain = row['chain']\n",
    "        true_label = row['class_index']\n",
    "        \n",
    "        # Get the predicted label for this image\n",
    "        image_index = test_df.index.get_loc(idx)  # Get the index of the image in test DataFrame\n",
    "        predicted_label = all_predictions[image_index]  # Use all_predictions instead of undefined predicted\n",
    "        \n",
    "        # Determine if the classification was correct\n",
    "        is_correct = (predicted_label == true_label)\n",
    "        \n",
    "        # Source and destination paths\n",
    "        src_path = os.path.join(image_dir, str(chain), image_name)\n",
    "        if is_correct:\n",
    "            dest_path = os.path.join(correct_dir, image_name)\n",
    "        else:\n",
    "            dest_path = os.path.join(incorrect_dir, image_name)\n",
    "        \n",
    "        # Copy the image\n",
    "        shutil.copy(src_path, dest_path)\n",
    "\n",
    "print(\"Image organization complete!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Worst classifications images have been organized.\n"
     ]
    }
   ],
   "source": [
    "#Let's also create a file of badly classified images to see why they were hard to classify\n",
    "\n",
    "# Define the hotel IDs and corresponding image directories\n",
    "worst_hotel_ids = [35545, 15195, 33836]\n",
    "\n",
    "# Paths\n",
    "image_dir = r\"C:\\ML_Project_Data\\train_images\"  # Root directory of images\n",
    "output_dir = r\"C:\\ML_Project_Data\\Worst_Classifications\"  # Output directory for organizing images\n",
    "\n",
    "# Create output directory if it doesn't exist\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Ensure the model is in evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Process test set and organize images for worst classifications\n",
    "with torch.no_grad():\n",
    "    for hotel_id in worst_hotel_ids:\n",
    "        # Create a directory for each hotel\n",
    "        hotel_dir = os.path.join(output_dir, str(hotel_id))\n",
    "        os.makedirs(hotel_dir, exist_ok=True)\n",
    "\n",
    "        # Filter test set for the current hotel ID\n",
    "        hotel_images = test_df[test_df['hotel_id'] == hotel_id]\n",
    "        \n",
    "        # Iterate through the images for this hotel ID\n",
    "        for idx, row in hotel_images.iterrows():\n",
    "            image_name = row['image']\n",
    "            chain = row['chain']\n",
    "\n",
    "            # Source and destination paths\n",
    "            src_path = os.path.join(image_dir, str(chain), image_name)\n",
    "            dest_path = os.path.join(hotel_dir, image_name)\n",
    "            \n",
    "            # Copy the image\n",
    "            shutil.copy(src_path, dest_path)\n",
    "\n",
    "print(\"Worst classifications images have been organized.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training images for worst classifications have been organized.\n"
     ]
    }
   ],
   "source": [
    "# Okay let's look at the training images for hte bad classifications\n",
    "\n",
    "# Paths\n",
    "training_output_dir = r\"C:\\ML_Project_Data\\Worst_Classifications\"  # Parent directory for worst classifications\n",
    "image_dir = r\"C:\\ML_Project_Data\\train_images\"  # Root directory of images\n",
    "\n",
    "# Ensure the directory exists\n",
    "os.makedirs(training_output_dir, exist_ok=True)\n",
    "\n",
    "# Process training set to organize images for specified hotels\n",
    "for hotel_id in worst_hotel_ids:\n",
    "    # Create a directory for the training images of each hotel\n",
    "    training_hotel_dir = os.path.join(training_output_dir, f\"{hotel_id}_training\")\n",
    "    os.makedirs(training_hotel_dir, exist_ok=True)\n",
    "\n",
    "    # Filter the training dataset for the current hotel ID\n",
    "    hotel_train_images = train_df[train_df['hotel_id'] == hotel_id]\n",
    "\n",
    "    # Iterate through the training images for this hotel ID\n",
    "    for idx, row in hotel_train_images.iterrows():\n",
    "        image_name = row['image']\n",
    "        chain = row['chain']\n",
    "\n",
    "        # Source and destination paths\n",
    "        src_path = os.path.join(image_dir, str(chain), image_name)\n",
    "        dest_path = os.path.join(training_hotel_dir, image_name)\n",
    "\n",
    "        # Copy the image\n",
    "        shutil.copy(src_path, dest_path)\n",
    "\n",
    "print(\"Training images for worst classifications have been organized.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Misclassified test and training images organized for worst classifications.\n"
     ]
    }
   ],
   "source": [
    "# Let's see what they were misclassified as\n",
    "\n",
    "# Paths\n",
    "output_dir = r\"C:\\ML_Project_Data\\Worst_Classifications\"  # Parent directory for worst classifications\n",
    "image_dir = r\"C:\\ML_Project_Data\\train_images\"  # Root directory of images\n",
    "\n",
    "# Ensure the output directory exists\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Ensure the model is in evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Process the worst hotels\n",
    "for hotel_id in worst_hotel_ids:\n",
    "    # Create directories for the misclassified test images\n",
    "    hotel_dir = os.path.join(output_dir, str(hotel_id))\n",
    "    misclassified_test_dir = os.path.join(hotel_dir, \"misclassified_test_images\")\n",
    "    misclassified_training_dir = os.path.join(hotel_dir, \"misclassified_training_images\")\n",
    "    os.makedirs(misclassified_test_dir, exist_ok=True)\n",
    "    os.makedirs(misclassified_training_dir, exist_ok=True)\n",
    "\n",
    "    # Filter the test dataset for the current hotel ID\n",
    "    hotel_test_images = test_df[test_df['hotel_id'] == hotel_id]\n",
    "\n",
    "    # Iterate through the test images for this hotel ID\n",
    "    for idx, row in hotel_test_images.iterrows():\n",
    "        image_name = row['image']\n",
    "        chain = row['chain']\n",
    "        true_label = row['class_index']\n",
    "\n",
    "        # Get the predicted label for this image\n",
    "        image_index = test_df.index.get_loc(idx)\n",
    "        predicted_label = all_predictions[image_index]  # Use predictions collected earlier\n",
    "        predicted_hotel_id = index_to_hotel_id[predicted_label]  # Map predicted label to hotel ID\n",
    "\n",
    "        # If the classification was incorrect\n",
    "        if true_label != predicted_label:\n",
    "            # Misclassified test image\n",
    "            src_path_test = os.path.join(image_dir, str(chain), image_name)\n",
    "            dest_path_test = os.path.join(misclassified_test_dir, f\"misclassified_as_{predicted_hotel_id}_{image_name}\")\n",
    "            shutil.copy(src_path_test, dest_path_test)\n",
    "\n",
    "            # Add the training images of the predicted hotel ID\n",
    "            predicted_training_images = train_df[train_df['hotel_id'] == predicted_hotel_id]\n",
    "            for _, train_row in predicted_training_images.iterrows():\n",
    "                train_image_name = train_row['image']\n",
    "                train_chain = train_row['chain']\n",
    "\n",
    "                src_path_train = os.path.join(image_dir, str(train_chain), train_image_name)\n",
    "                dest_path_train = os.path.join(misclassified_training_dir, f\"from_{predicted_hotel_id}_{train_image_name}\")\n",
    "                shutil.copy(src_path_train, dest_path_train)\n",
    "\n",
    "print(\"Misclassified test and training images organized for worst classifications.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's set up images for TCAV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All images for hotel ID 4869 have been copied to C:\\ML_Project_Data\\TCAV\\4869.\n"
     ]
    }
   ],
   "source": [
    "# Okay let's gather all the images for the class that we want to run TCAV on\n",
    "\n",
    "# Define the target hotel ID\n",
    "target_hotel_id = 4869\n",
    "\n",
    "# Define paths\n",
    "train_image_dir = r\"C:\\ML_Project_Data\\train_images\"  # Root directory of training images\n",
    "output_dir = r\"C:\\ML_Project_Data\\TCAV\\4869\"  # Directory for this hotel's images\n",
    "\n",
    "# Ensure the output directory exists\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Combine training and testing datasets\n",
    "combined_df = pd.concat([train_df, test_df])\n",
    "\n",
    "# Filter images for the target hotel ID\n",
    "hotel_images = combined_df[combined_df['hotel_id'] == target_hotel_id]\n",
    "\n",
    "# Copy images to the target directory\n",
    "for _, row in hotel_images.iterrows():\n",
    "    image_name = row['image']\n",
    "    chain_id = row['chain']  # Retrieve the chain ID\n",
    "    src_path = os.path.join(train_image_dir, str(chain_id), image_name)  # Construct source path\n",
    "    dest_path = os.path.join(output_dir, image_name)  # Construct destination path\n",
    "\n",
    "    # Copy image\n",
    "    shutil.copy(src_path, dest_path)\n",
    "\n",
    "print(f\"All images for hotel ID {target_hotel_id} have been copied to {output_dir}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concept 'carpet': 8 existing images.\n",
      "Augmenting 22 images for 'carpet'...\n",
      "Concept 'painting': 21 existing images.\n",
      "Augmenting 9 images for 'painting'...\n",
      "Image augmentation complete!\n"
     ]
    }
   ],
   "source": [
    "# Now let's use image augmentation to create more triaiing images for each concept\n",
    "\n",
    "import os\n",
    "import random\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "\n",
    "# Paths\n",
    "base_dir = r\"C:\\ML_Project_Data\\TCAV\\4869\"  # Root directory containing concept folders\n",
    "concepts = [\"carpet\", \"painting\"] #,\"bed\", \"lamp\",]  # List of concepts\n",
    "target_count = 30  # Target number of training images per concept\n",
    "\n",
    "# Define augmentation transforms\n",
    "augmentation_transforms = transforms.Compose([\n",
    "    transforms.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.3, hue=0.1),\n",
    "    transforms.RandomRotation(degrees=15),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),\n",
    "    transforms.Resize((224, 224)),  # Resize to match model input size\n",
    "    transforms.ToTensor()  # Convert image to tensor\n",
    "])\n",
    "\n",
    "# Loop through each concept folder\n",
    "for concept in concepts:\n",
    "    concept_path = os.path.join(base_dir, concept, \"training\")  # Training images folder\n",
    "    augmented_path = os.path.join(base_dir, concept, \"training_augmented\")  # Augmented images folder\n",
    "    os.makedirs(augmented_path, exist_ok=True)\n",
    "\n",
    "    # List all existing images in the concept folder\n",
    "    image_files = [f for f in os.listdir(concept_path) if os.path.isfile(os.path.join(concept_path, f))]\n",
    "\n",
    "    # Count current images\n",
    "    current_count = len(image_files)\n",
    "    print(f\"Concept '{concept}': {current_count} existing images.\")\n",
    "\n",
    "    # If images are fewer than the target, augment until we have target_count\n",
    "    if current_count < target_count:\n",
    "        required_augmentations = target_count - current_count\n",
    "        print(f\"Augmenting {required_augmentations} images for '{concept}'...\")\n",
    "\n",
    "        for i in range(required_augmentations):\n",
    "            # Pick a random image to augment\n",
    "            img_file = random.choice(image_files)\n",
    "            img_path = os.path.join(concept_path, img_file)\n",
    "\n",
    "            # Open the image\n",
    "            image = Image.open(img_path).convert(\"RGB\")\n",
    "\n",
    "            # Apply augmentation\n",
    "            augmented_image = augmentation_transforms(image)\n",
    "\n",
    "            # Convert tensor back to PIL Image\n",
    "            augmented_image = transforms.ToPILImage()(augmented_image)\n",
    "\n",
    "            # Save augmented image\n",
    "            augmented_filename = f\"augmented_{i+1}_{img_file}\"\n",
    "            augmented_image.save(os.path.join(augmented_path, augmented_filename))\n",
    "\n",
    "    else:\n",
    "        print(f\"No augmentation needed for '{concept}'.\")\n",
    "\n",
    "print(\"Image augmentation complete!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying random images for concept: carpet\n",
      "Copying random images for concept: painting\n",
      "Random images copied to each concept folder.\n"
     ]
    }
   ],
   "source": [
    "# now let's gather random images to train against\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "import random\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "\n",
    "# Parameters\n",
    "target_hotel_id = 4869  # Hotel ID to exclude\n",
    "num_random_images = 40  # Number of random images needed per concept\n",
    "concepts = [\"carpet\", \"painting\"] #,\"bed\", \"lamp\",]   # List of concepts\n",
    "\n",
    "# Paths\n",
    "image_dir = r\"C:\\ML_Project_Data\\train_images\"  # Root directory of images\n",
    "output_dir = r\"C:\\ML_Project_Data\\TCAV\\4869\"  # Directory where concept folders exist\n",
    "\n",
    "# Filter the dataset to exclude the target hotel\n",
    "non_target_df = test_df[test_df['hotel_id'] != target_hotel_id]\n",
    "\n",
    "# Shuffle the non-target DataFrame to randomize\n",
    "non_target_df = non_target_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Ensure we have enough images for selection\n",
    "assert len(non_target_df) >= num_random_images, \"Not enough non-target images available.\"\n",
    "\n",
    "# Randomly select 70 images\n",
    "selected_random_images = non_target_df.sample(n=num_random_images, random_state=42)\n",
    "\n",
    "# Iterate through each concept\n",
    "for concept in concepts:\n",
    "    # Create the 'random' folder within the concept folder\n",
    "    concept_random_dir = os.path.join(output_dir, concept, \"random\")\n",
    "    os.makedirs(concept_random_dir, exist_ok=True)\n",
    "\n",
    "    print(f\"Copying random images for concept: {concept}\")\n",
    "\n",
    "    # Copy the selected random images to the 'random' folder\n",
    "    for _, row in selected_random_images.iterrows():\n",
    "        image_name = row['image']\n",
    "        chain = row['chain']\n",
    "        \n",
    "        # Construct source and destination paths\n",
    "        src_path = os.path.join(image_dir, str(chain), image_name)\n",
    "        dest_path = os.path.join(concept_random_dir, image_name)\n",
    "        \n",
    "        # Copy the image\n",
    "        shutil.copy(src_path, dest_path)\n",
    "\n",
    "print(\"Random images copied to each concept folder.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Model & Extract Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set device to GPU if available\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "MODEL_PATH = r\"C:\\Users\\linds\\OneDrive\\Documents\\MSBA-lindsayslaptop\\Fall\\Advanced Machine Learning\\Best Model.pth\"\n",
    "\n",
    "# Parameters\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "# Paths\n",
    "concepts = [\"carpet\", \"painting\"] #,\"bed\", \"lamp\",] \n",
    "base_dir = r\"C:\\ML_Project_Data\\TCAV\\4869\"\n",
    "random_dir_name = \"random\"\n",
    "train_dir_names = [\"training\", \"training_augmented\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define transforms\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset Class\n",
    "class ConceptImageDataset(Dataset):\n",
    "    def __init__(self, image_paths, transform=None):\n",
    "        self.image_paths = image_paths\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, img_path  # Return the image and its path for reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\linds\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\linds\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n",
      "C:\\Users\\linds\\AppData\\Local\\Temp\\ipykernel_22492\\2779405803.py:7: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(MODEL_PATH, map_location=DEVICE))  # Load the fine-tuned weights\n"
     ]
    }
   ],
   "source": [
    "# Load ResNet-50 Architecture\n",
    "model = models.resnet50(pretrained=False)  # Use the same architecture as during training\n",
    "num_classes = 1062  # Match the number of classes in the dataset\n",
    "model.fc = torch.nn.Linear(model.fc.in_features, num_classes)  # Restore the original `fc` layer\n",
    "\n",
    "# Load Pretrained Weights\n",
    "model.load_state_dict(torch.load(MODEL_PATH, map_location=DEVICE))  # Load the fine-tuned weights\n",
    "model = model.to(DEVICE)\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "# Modify the Model for Feature Extraction\n",
    "# Extract features from the avgpool layer (1x2048 feature vector)\n",
    "feature_extractor = torch.nn.Sequential(*list(model.children())[:-2])  # Remove `fc` and `avgpool`\n",
    "avgpool = torch.nn.AdaptiveAvgPool2d((1, 1))  # Add avgpool manually for feature extraction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(image_paths, model, transform, batch_size=16):\n",
    "    dataset = ConceptImageDataset(image_paths, transform=transform)\n",
    "    loader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    features = []\n",
    "    paths = []\n",
    "    with torch.no_grad():\n",
    "        for images, img_paths in loader:\n",
    "            images = images.to(DEVICE)\n",
    "            outputs = model(images)  # Extract spatial features\n",
    "            outputs = avgpool(outputs)  # Apply global average pooling\n",
    "            outputs = torch.flatten(outputs, 1)  # Flatten to (batch_size x 2048)\n",
    "            features.append(outputs.cpu().numpy())\n",
    "            paths.extend(img_paths)\n",
    "\n",
    "    features = np.concatenate(features, axis=0)  # Combine all features into a single array\n",
    "    return features, paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting features for concept 'carpet'...\n",
      "Extracting features for testing images in 'carpet'...\n",
      "Feature extraction complete for 'carpet'. Features saved.\n",
      "Extracting features for concept 'painting'...\n",
      "Extracting features for testing images in 'painting'...\n",
      "Feature extraction complete for 'painting'. Features saved.\n",
      "Feature extraction completed for all concepts.\n"
     ]
    }
   ],
   "source": [
    "# Updated Feature Extraction Script\n",
    "for concept in concepts:\n",
    "    concept_dir = os.path.join(base_dir, concept)\n",
    "\n",
    "    # Gather all image paths for training and training_augmented\n",
    "    concept_image_paths = []\n",
    "    for train_dir in train_dir_names:\n",
    "        train_path = os.path.join(concept_dir, train_dir)\n",
    "        concept_image_paths += [os.path.join(train_path, f) for f in os.listdir(train_path) if os.path.isfile(os.path.join(train_path, f))]\n",
    "\n",
    "    # Gather random image paths\n",
    "    random_dir = os.path.join(concept_dir, random_dir_name)\n",
    "    random_image_paths = [os.path.join(random_dir, f) for f in os.listdir(random_dir) if os.path.isfile(os.path.join(random_dir, f))]\n",
    "\n",
    "    # Gather testing image paths\n",
    "    testing_dir = os.path.join(concept_dir, \"testing\")\n",
    "    testing_image_paths = [os.path.join(testing_dir, f) for f in os.listdir(testing_dir) if os.path.isfile(os.path.join(testing_dir, f))]\n",
    "\n",
    "    # Check if paths are not empty\n",
    "    if not concept_image_paths:\n",
    "        print(f\"No concept images found for '{concept}'. Skipping...\")\n",
    "        continue\n",
    "    if not random_image_paths:\n",
    "        print(f\"No random images found for '{concept}'. Skipping...\")\n",
    "        continue\n",
    "    if not testing_image_paths:\n",
    "        print(f\"No testing images found for '{concept}'. Skipping...\")\n",
    "        continue\n",
    "\n",
    "    # Extract features for concept, random, and testing images\n",
    "    print(f\"Extracting features for concept '{concept}'...\")\n",
    "\n",
    "    # Concept and random images\n",
    "    concept_features, concept_paths = extract_features(concept_image_paths, feature_extractor, transform, BATCH_SIZE)\n",
    "    random_features, random_paths = extract_features(random_image_paths, feature_extractor, transform, BATCH_SIZE)\n",
    "\n",
    "    # Testing images\n",
    "    print(f\"Extracting features for testing images in '{concept}'...\")\n",
    "    testing_features, testing_paths = extract_features(testing_image_paths, feature_extractor, transform, BATCH_SIZE)\n",
    "\n",
    "    # Save features and paths for later use\n",
    "    np.save(os.path.join(concept_dir, \"concept_features.npy\"), concept_features)\n",
    "    np.save(os.path.join(concept_dir, \"concept_paths.npy\"), concept_paths)\n",
    "    np.save(os.path.join(concept_dir, \"random_features.npy\"), random_features)\n",
    "    np.save(os.path.join(concept_dir, \"random_paths.npy\"), random_paths)\n",
    "    np.save(os.path.join(concept_dir, \"testing_features.npy\"), testing_features)\n",
    "    np.save(os.path.join(concept_dir, \"testing_paths.npy\"), testing_paths)\n",
    "\n",
    "    print(f\"Feature extraction complete for '{concept}'. Features saved.\")\n",
    "\n",
    "print(\"Feature extraction completed for all concepts.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Concept Vectors "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy for 'carpet': 1.00\n",
      "CAV for concept 'carpet' trained and saved.\n",
      "Validation Accuracy for 'painting': 1.00\n",
      "CAV for concept 'painting' trained and saved.\n",
      "All classifiers trained and saved.\n"
     ]
    }
   ],
   "source": [
    "# now let's train the linear classifiers\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "# Paths and parameters\n",
    "concepts = [\"carpet\", \"painting\"] #,\"bed\"] \n",
    "base_dir = r\"C:\\ML_Project_Data\\TCAV\\4869\"\n",
    "\n",
    "# Train linear classifiers for each concept\n",
    "for concept in concepts:\n",
    "    concept_dir = os.path.join(base_dir, concept)\n",
    "\n",
    "    # Load features\n",
    "    concept_features = np.load(os.path.join(concept_dir, \"concept_features.npy\"))\n",
    "    random_features = np.load(os.path.join(concept_dir, \"random_features.npy\"))\n",
    "\n",
    "    # Combine features and labels\n",
    "    X = np.concatenate([concept_features, random_features], axis=0)\n",
    "    y = np.concatenate([np.ones(len(concept_features)), np.zeros(len(random_features))], axis=0)  # 1 for concept, 0 for random\n",
    "\n",
    "    # Train-test split (80% train, 20% test)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "    # Standardize features using training set\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_val_scaled = scaler.transform(X_val)\n",
    "\n",
    "    # Train logistic regression classifier\n",
    "    clf = LogisticRegression(random_state=42, max_iter=1000)\n",
    "    clf.fit(X_train_scaled, y_train)\n",
    "\n",
    "    # Evaluate the classifier\n",
    "    y_pred = clf.predict(X_val_scaled)\n",
    "    accuracy = accuracy_score(y_val, y_pred)\n",
    "    print(f\"Validation Accuracy for '{concept}': {accuracy:.2f}\")\n",
    "\n",
    "    # Save the classifier and scaler\n",
    "    with open(os.path.join(concept_dir, f\"{concept}_cav.pkl\"), \"wb\") as cav_file:\n",
    "        pickle.dump((clf, scaler), cav_file)\n",
    "\n",
    "    print(f\"CAV for concept '{concept}' trained and saved.\")\n",
    "\n",
    "print(\"All classifiers trained and saved.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TCAV Scores and Directional Derivatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TCAV Score for 'carpet': 0.10\n",
      "TCAV Score for 'painting': 0.50\n",
      "TCAV Score Calculation Complete.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Paths and Parameters\n",
    "concepts = [\"carpet\", \"painting\"] #,\"bed\"] \n",
    "base_dir = r\"C:\\ML_Project_Data\\TCAV\\4869\"\n",
    "\n",
    "# Dictionary to store TCAV results\n",
    "tcav_scores = {}\n",
    "\n",
    "# Iterate through each concept\n",
    "for concept in concepts:\n",
    "    concept_dir = os.path.join(base_dir, concept)\n",
    "\n",
    "    # Load CAV (Classifier and Scaler)\n",
    "    cav_file_path = os.path.join(concept_dir, f\"{concept}_cav.pkl\")\n",
    "    with open(cav_file_path, \"rb\") as f:\n",
    "        clf, scaler = pickle.load(f)\n",
    "\n",
    "    # Load testing features and paths\n",
    "    testing_features = np.load(os.path.join(concept_dir, \"testing_features.npy\"))\n",
    "    testing_paths = np.load(os.path.join(concept_dir, \"testing_paths.npy\"), allow_pickle=True)\n",
    "\n",
    "    # Standardize the testing features\n",
    "    testing_features_scaled = scaler.transform(testing_features)\n",
    "\n",
    "    # Predict using the trained classifier\n",
    "    predictions = clf.predict(testing_features_scaled)\n",
    "    probabilities = clf.predict_proba(testing_features_scaled)[:, 1]  # Probability of concept presence\n",
    "\n",
    "    # Calculate TCAV score (fraction of images classified as concept)\n",
    "    tcav_score = predictions.mean()  # Average of 1s (concept detected)\n",
    "    print(f\"TCAV Score for '{concept}': {tcav_score:.2f}\")\n",
    "\n",
    "    # Save TCAV results\n",
    "    tcav_scores[concept] = {\n",
    "        \"tcav_score\": tcav_score,\n",
    "        \"predictions\": predictions,\n",
    "        \"probabilities\": probabilities,\n",
    "        \"testing_paths\": testing_paths,\n",
    "    }\n",
    "\n",
    "print(\"TCAV Score Calculation Complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Directional Derivative for 'carpet': 0.2233\n",
      "Average Directional Derivative for 'painting': 0.2824\n",
      "Directional Derivative Calculation Complete.\n"
     ]
    }
   ],
   "source": [
    "#Now let's get the directional derivatives\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "from torch.nn import Linear\n",
    "\n",
    "# Paths and Parameters\n",
    "concepts = [\"carpet\", \"painting\"] \n",
    "base_dir = r\"C:\\ML_Project_Data\\TCAV\\4869\"\n",
    "\n",
    "# Store directional derivatives\n",
    "directional_derivatives = {}\n",
    "\n",
    "# Enable gradient tracking globally\n",
    "torch.set_grad_enabled(True)\n",
    "\n",
    "# Calculate directional derivatives for each concept\n",
    "for concept in concepts:\n",
    "    concept_dir = os.path.join(base_dir, concept)\n",
    "\n",
    "    # Load CAV (Classifier and Scaler)\n",
    "    cav_file_path = os.path.join(concept_dir, f\"{concept}_cav.pkl\")\n",
    "    with open(cav_file_path, \"rb\") as f:\n",
    "        clf, scaler = pickle.load(f)\n",
    "\n",
    "    # Load testing features and paths\n",
    "    testing_features = np.load(os.path.join(concept_dir, \"testing_features.npy\"))\n",
    "    testing_paths = np.load(os.path.join(concept_dir, \"testing_paths.npy\"), allow_pickle=True)\n",
    "\n",
    "    # Convert features to PyTorch tensors with gradient tracking enabled\n",
    "    testing_features_tensor = torch.tensor(testing_features, dtype=torch.float32, requires_grad=True).to(DEVICE)\n",
    "\n",
    "    # Retain gradient explicitly (required for non-leaf tensors)\n",
    "    testing_features_tensor.retain_grad()\n",
    "\n",
    "    # Define CAV as a trainable linear layer\n",
    "    linear_layer = Linear(testing_features_tensor.shape[1], 1).to(DEVICE)\n",
    "\n",
    "    # Assign weights and bias from the loaded classifier\n",
    "    with torch.no_grad():\n",
    "        linear_layer.weight.copy_(torch.tensor(clf.coef_, dtype=torch.float32).to(DEVICE))\n",
    "        linear_layer.bias.copy_(torch.tensor(clf.intercept_, dtype=torch.float32).to(DEVICE))\n",
    "\n",
    "    # Forward pass through the linear layer\n",
    "    logits = linear_layer(testing_features_tensor)\n",
    "\n",
    "    # Simulate a loss to enable backpropagation\n",
    "    loss = logits.sum()\n",
    "    loss.backward()\n",
    "\n",
    "    # Extract gradients\n",
    "    if testing_features_tensor.grad is None:\n",
    "        raise RuntimeError(\"Gradients were not computed. Ensure requires_grad=True and autograd is enabled.\")\n",
    "\n",
    "    gradients = testing_features_tensor.grad.cpu().numpy()\n",
    "\n",
    "    # Calculate directional derivatives\n",
    "    cav_vector = linear_layer.weight.detach().cpu().numpy().flatten()\n",
    "    derivatives = np.dot(gradients, cav_vector)\n",
    "\n",
    "    # Average directional derivative\n",
    "    avg_derivative = np.mean(derivatives)\n",
    "\n",
    "    # Print results\n",
    "    print(f\"Average Directional Derivative for '{concept}': {avg_derivative:.4f}\")\n",
    "\n",
    "    # Store results\n",
    "    directional_derivatives[concept] = {\n",
    "        \"derivatives\": derivatives,\n",
    "        \"average_derivative\": avg_derivative,\n",
    "        \"testing_paths\": testing_paths,\n",
    "    }\n",
    "\n",
    "print(\"Directional Derivative Calculation Complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Directional Derivative for 'bed': 0.3481\n",
      "Directional Derivative Calculation Complete.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "from torch.nn import Linear\n",
    "\n",
    "# Paths and Parameters\n",
    "concepts = [\"bed\"] \n",
    "base_dir = r\"C:\\ML_Project_Data\\TCAV_First_attempt\\4869\"\n",
    "\n",
    "# Store directional derivatives\n",
    "directional_derivatives = {}\n",
    "\n",
    "# Enable gradient tracking globally\n",
    "torch.set_grad_enabled(True)\n",
    "\n",
    "# Calculate directional derivatives for each concept\n",
    "for concept in concepts:\n",
    "    concept_dir = os.path.join(base_dir, concept)\n",
    "\n",
    "    # Load CAV (Classifier and Scaler)\n",
    "    cav_file_path = os.path.join(concept_dir, f\"{concept}_cav.pkl\")\n",
    "    with open(cav_file_path, \"rb\") as f:\n",
    "        clf, scaler = pickle.load(f)\n",
    "\n",
    "    # Load testing features and paths\n",
    "    testing_features = np.load(os.path.join(concept_dir, \"testing_features.npy\"))\n",
    "    testing_paths = np.load(os.path.join(concept_dir, \"testing_paths.npy\"), allow_pickle=True)\n",
    "\n",
    "    # Convert features to PyTorch tensors with gradient tracking enabled\n",
    "    testing_features_tensor = torch.tensor(testing_features, dtype=torch.float32, requires_grad=True).to(DEVICE)\n",
    "\n",
    "    # Retain gradient explicitly (required for non-leaf tensors)\n",
    "    testing_features_tensor.retain_grad()\n",
    "\n",
    "    # Define CAV as a trainable linear layer\n",
    "    linear_layer = Linear(testing_features_tensor.shape[1], 1).to(DEVICE)\n",
    "\n",
    "    # Assign weights and bias from the loaded classifier\n",
    "    with torch.no_grad():\n",
    "        linear_layer.weight.copy_(torch.tensor(clf.coef_, dtype=torch.float32).to(DEVICE))\n",
    "        linear_layer.bias.copy_(torch.tensor(clf.intercept_, dtype=torch.float32).to(DEVICE))\n",
    "\n",
    "    # Forward pass through the linear layer\n",
    "    logits = linear_layer(testing_features_tensor)\n",
    "\n",
    "    # Simulate a loss to enable backpropagation\n",
    "    loss = logits.sum()\n",
    "    loss.backward()\n",
    "\n",
    "    # Extract gradients\n",
    "    if testing_features_tensor.grad is None:\n",
    "        raise RuntimeError(\"Gradients were not computed. Ensure requires_grad=True and autograd is enabled.\")\n",
    "\n",
    "    gradients = testing_features_tensor.grad.cpu().numpy()\n",
    "\n",
    "    # Calculate directional derivatives\n",
    "    cav_vector = linear_layer.weight.detach().cpu().numpy().flatten()\n",
    "    derivatives = np.dot(gradients, cav_vector)\n",
    "\n",
    "    # Average directional derivative\n",
    "    avg_derivative = np.mean(derivatives)\n",
    "\n",
    "    # Print results\n",
    "    print(f\"Average Directional Derivative for '{concept}': {avg_derivative:.4f}\")\n",
    "\n",
    "    # Store results\n",
    "    directional_derivatives[concept] = {\n",
    "        \"derivatives\": derivatives,\n",
    "        \"average_derivative\": avg_derivative,\n",
    "        \"testing_paths\": testing_paths,\n",
    "    }\n",
    "\n",
    "print(\"Directional Derivative Calculation Complete.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
